{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![londonr-banner-logo](../images/londonr-banner.png)](https://www.londonr.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: right\"><font size = 3 color = \"#B22222\" face = \"verdana\"><b>- LondonR - Python for R Users - </b></font></div>\n",
    "<div style = \"text-align: right\"><font><i>By 'Dayo Oguntoyinbo</i></font></div>\n",
    "<div style = \"text-align: right\"><font>16th December 2019</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E - Modelling and Code Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Options for all cells \n",
    "import pandas as pd\n",
    "# change display setting of pandas\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "# Setting the graphics\n",
    "%matplotlib inline\n",
    "# suppress all warnings (since anova gives a warning)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tips = pd.read_csv(\"../Data/tips.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D1 - Statistical Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of packages that contain functions for statistics and modelling in the Python standard library. We will use the **statsmodel** package which contains a large number of models and statistical tests, organised in several modules. Some of the more common model fitting functions can be found in the following table:\n",
    "\n",
    "| Package/Module | Function | Model |\n",
    "|----------------|----------|-------|\n",
    "| `statsmodels.formula.api` | `ols`/`OLS` | Linear Regression by OLS (Ordinary Least Squares) |\n",
    "| `statsmodels.formula.api` | `gls`/`GLS` | Linear Regression by GLS (Generalised Least Squares) |\n",
    "| `statsmodels.api` | `GLM` | GLM (Generalised Linear Model) |\n",
    "| `statsmodels.api` | `RLM` | RLM (Robust Linear Model) |\n",
    "| `statsmodels.tsa.arima_model` | `ARIMA` | Time Series Analysis - ARIMA Model |\n",
    "| `statsmodels.formula.api` | `phreg` | Survival Analysis - Cox Models |\n",
    "| `statsmodels.api` | `stats.anova_lm` | ANOVA (Analysis of Variance)\n",
    "\n",
    "\n",
    "For a full list of functionality, see the package's site [http://www.statsmodels.org/dev/index.html](http://www.statsmodels.org/dev/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to modelling in R, the model is specified through a formula with a tilde (`~`) which typically has the response on the left-hand side and the independent variables on the right-hand side. The standard formula notation is the same as in R, e.g.,\n",
    "\n",
    "| Python Formula | Model | Actual Model Formula |\n",
    "|----------------|-------|----------------------|\n",
    "| `y ~ x` | Y against X + an intercept | $y = a + bx + \\epsilon$ |\n",
    "| `y ~ x-1` | Y against X (no intercept) | $y = bx + \\epsilon$ |\n",
    "| `y ~ x+z` | Y against X and Z + an intercept | $y = a + bx + cz + \\epsilon$ |\n",
    "| `y ~ x:z` | Y against the X/Z interaction term | $y = a + bxz + \\epsilon$ |\n",
    "\n",
    "where in the actual model formulae above, $\\epsilon$ is the error term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R, we typically provide a modelling function with the formula and the data and it returns a fitted model. Here, model specification and model fitting are two separate steps. Using the `ols` function, we specify a linear model for the tip as explained by the total amount of the bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "m1 = smf.ols(formula=\"tip ~ total_bill\", data=tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting model object has a `.fit` method which is then used to estimate the parameters of the model. For the fitted model object, further methods and attributes are available, e.g., a summary method (`.summary`) and the estimated parameters (`.params`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    tip   R-squared:                       0.457\n",
      "Model:                            OLS   Adj. R-squared:                  0.454\n",
      "Method:                 Least Squares   F-statistic:                     203.4\n",
      "Date:                Mon, 16 Dec 2019   Prob (F-statistic):           6.69e-34\n",
      "Time:                        13:33:11   Log-Likelihood:                -350.54\n",
      "No. Observations:                 244   AIC:                             705.1\n",
      "Df Residuals:                     242   BIC:                             712.1\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.9203      0.160      5.761      0.000       0.606       1.235\n",
      "total_bill     0.1050      0.007     14.260      0.000       0.091       0.120\n",
      "==============================================================================\n",
      "Omnibus:                       20.185   Durbin-Watson:                   2.151\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.750\n",
      "Skew:                           0.443   Prob(JB):                     6.35e-09\n",
      "Kurtosis:                       4.711   Cond. No.                         53.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mf1 = m1.fit()\n",
    "print(mf1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Fit a linear model for `tip` as explained through `total_bill` and `smoker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    tip   R-squared:                       0.459\n",
      "Model:                            OLS   Adj. R-squared:                  0.455\n",
      "Method:                 Least Squares   F-statistic:                     102.4\n",
      "Date:                Mon, 16 Dec 2019   Prob (F-statistic):           6.57e-33\n",
      "Time:                        13:33:11   Log-Likelihood:                -349.93\n",
      "No. Observations:                 244   AIC:                             705.9\n",
      "Df Residuals:                     241   BIC:                             716.3\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         0.9632      0.164      5.861      0.000       0.639       1.287\n",
      "smoker[T.Yes]    -0.1489      0.135     -1.102      0.272      -0.415       0.117\n",
      "total_bill        0.1057      0.007     14.309      0.000       0.091       0.120\n",
      "==============================================================================\n",
      "Omnibus:                       23.655   Durbin-Watson:                   2.150\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.834\n",
      "Skew:                           0.524   Prob(JB):                     3.03e-10\n",
      "Kurtosis:                       4.792   Cond. No.                         57.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Solutions\n",
    "import statsmodels.formula.api as smf\n",
    "model_s = smf.ols(formula=\"tip ~ total_bill + smoker\", data=tips)\n",
    "print(model_s.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can fit a model with an interaction between `total_bill` and `smoker`, and compare this to the simpler model via an ANOVA (analysis of variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   df_resid         ssr  df_diff    ss_diff          F    Pr(>F)\n",
       "0     242.0  252.788744      0.0        NaN        NaN       NaN\n",
       "1     240.0  229.809386      2.0  22.979358  11.999175  0.000011"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "mf2 = (\n",
    "    smf\n",
    "    .ols(formula=\"tip ~ total_bill + smoker + total_bill:smoker\",\n",
    "         data=tips)\n",
    "    .fit()\n",
    ")\n",
    "\n",
    "# or total_bill*smoker #mf2.summary()\n",
    "sm.stats.anova_lm(mf1, mf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning : Python Warnings**\n",
    "\n",
    "You may notice a warning appear when running the above function. This occurs due to the `NaN` values in our output; however, this function will always produce NaN values there so this is nothing to worry about.\n",
    "\n",
    "Warnings appear red in Jupyter, but do not stop the computation of the function, so can *in some cases* be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D2 - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While R has its strength in statistical modelling, Python shines in machine learning, in particular with the **scikit-learn** package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data in the Right Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we stored all our data in one `DataFrame`. The functions in **scikit-learn** for models and algorithms expect the features, or explanatory variables, and the target, or response, in two separate objects: The features are in a 2-dimensional array with one row per sample or observation and one column per feature or variable. The target is in an one-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a `DataFrame` using the `values` attribute. Here we will use the tips data to create an array of features and the one-dimensional array of the tips as our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tips_data = tips.drop(\"tip\", axis=1).values\n",
    "tips_target = tips[\"tip\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example datasets in **scikit-learn** come in form of dictionaries which hold the two arrays for features and target along with the corresponding names. Here we will use the iris data which contains three different species of iris flowers as the target and four different measurements (length and width of the sepal and petal, respectively) as the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will use the generic names `X` and `y` for the features and target, respectively. Python allows us to assign multiple objects at once as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is common machine learning task so we will use this as example to illustrate a common workflow with **scikit-learn**. \n",
    "\n",
    "Similar to working with **statsmodel**, specifying a model, also called instantiating a model, is a separate step from fitting a model. Here we will first instantiate a K-nearest neighbor classifier and then fit it on the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "# Creates the model\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fits the model\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions can be accessed with the `.predict` method for the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor']\n"
     ]
    }
   ],
   "source": [
    "# What kind of iris has 3cm x 5cm sepal and 4cm x 2cm petal?\n",
    "\n",
    "# Tests prediction\n",
    "result = knn.predict([[3, 5, 4, 2],])\n",
    "print(iris.target_names[result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions can be used to calculate the accuracy of the predictions. However, choosing a model based on its accuracy on the same data that was used to fit the model often leads to choosing a model too closely adapted to the data.\n",
    "\n",
    "To avoid this over-fitting, the data is typically split into train and test data. We can easily do this with the `train_test_split` function and then train our classifier only on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also available as a method, `.score`, for the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation takes this idea a step further: The data is split into k folds and the model is fit k times, always leaving one of the folds as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "cv = model_selection.cross_val_score(neighbors.KNeighborsClassifier(5), X, y, cv=10)\n",
    "cv.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modules in **scikit-learn** are designed such that we can easily swap out one model for another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "1. Use the `SVC` function from `sklearn.svm` to solve the iris classification problem with a support vector classifier. What is the accuracy on the training set?\n",
    "\n",
    "Extension:\n",
    "\n",
    "2. What is the average accuracy when using a 10-fold cross-validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from sklearn import svm \n",
    "\n",
    "svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800000000000001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = model_selection.cross_val_score(svm.SVC(), X, y, cv=10)\n",
    "cv.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look up the use of `F1-score`, `Jaccard Index`, `Confusion Matrix`, `ROC-AUC` and soon for additional understanding on metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D3 - Code Editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section, we shall use `SublimeText`. Please see provided code base folder `shapes-va`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; Mango Solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
